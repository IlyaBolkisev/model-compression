{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c330cf-90f2-428d-b5c3-aa2ba4a4d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f2cfb5-f2ce-4fa3-83e6-09395c7ccfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ad202-686c-4860-8547-06d7b92b1402",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4144ac-d34c-4583-8917-c7f45321810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "val_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                std=[0.2023, 0.1994, 0.2010])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f91332b8-7352-4dec-b020-aaceba6e9623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
    "val_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e595e7d5-14e1-4942-be25-19a60bcd6a44",
   "metadata": {},
   "source": [
    "# Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02daef98-a1d7-4f2a-a321-5ad02cf5c332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       1,728\n",
      "|    └─BatchNorm2d: 2-2                  128\n",
      "|    └─ReLU: 2-3                         --\n",
      "|    └─Conv2d: 2-4                       36,864\n",
      "|    └─BatchNorm2d: 2-5                  128\n",
      "|    └─ReLU: 2-6                         --\n",
      "|    └─MaxPool2d: 2-7                    --\n",
      "├─Sequential: 1-2                        --\n",
      "|    └─Conv2d: 2-8                       73,728\n",
      "|    └─BatchNorm2d: 2-9                  256\n",
      "|    └─ReLU: 2-10                        --\n",
      "|    └─Conv2d: 2-11                      147,456\n",
      "|    └─BatchNorm2d: 2-12                 256\n",
      "|    └─ReLU: 2-13                        --\n",
      "|    └─MaxPool2d: 2-14                   --\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─Conv2d: 2-15                      294,912\n",
      "|    └─BatchNorm2d: 2-16                 512\n",
      "|    └─ReLU: 2-17                        --\n",
      "|    └─Conv2d: 2-18                      589,824\n",
      "|    └─BatchNorm2d: 2-19                 512\n",
      "|    └─ReLU: 2-20                        --\n",
      "|    └─MaxPool2d: 2-21                   --\n",
      "├─Sequential: 1-4                        --\n",
      "|    └─Conv2d: 2-22                      1,179,648\n",
      "|    └─BatchNorm2d: 2-23                 1,024\n",
      "|    └─ReLU: 2-24                        --\n",
      "|    └─Conv2d: 2-25                      2,359,296\n",
      "|    └─BatchNorm2d: 2-26                 1,024\n",
      "|    └─ReLU: 2-27                        --\n",
      "|    └─MaxPool2d: 2-28                   --\n",
      "├─Sequential: 1-5                        --\n",
      "|    └─Linear: 2-29                      4,196,352\n",
      "|    └─ReLU: 2-30                        --\n",
      "|    └─Linear: 2-31                      2,098,176\n",
      "|    └─ReLU: 2-32                        --\n",
      "|    └─Linear: 2-33                      10,250\n",
      "=================================================================\n",
      "Total params: 10,992,074\n",
      "Trainable params: 10,992,074\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.block1 = self._make_conv_block(in_ch=3,   out_ch=64)\n",
    "        self.block2 = self._make_conv_block(in_ch=64,  out_ch=128)\n",
    "        self.block3 = self._make_conv_block(in_ch=128, out_ch=256)\n",
    "        self.block4 = self._make_conv_block(in_ch=256, out_ch=512)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 2048),  # из 512x2x2 -> 2048\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def _make_conv_block(self, in_ch, out_ch):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x) \n",
    "        x = self.block2(x)  \n",
    "        x = self.block3(x)  \n",
    "        x = self.block4(x) \n",
    "\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = CNN(num_classes=10).to(DEVICE)\n",
    "\n",
    "_ = summary(model, input_size=(BATCH_SIZE, 3, 32, 32), device=DEVICE, depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80bd0a1-d26f-4f0a-8b6f-ce93aaa537af",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "333e3e55-44d7-4e76-8c40-d3fde28a3eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1db35a1-686c-4337-9ac6-8a9ddaef1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X_, y_ in dataloader:\n",
    "        X_, y_ = X_.to(DEVICE), y_.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_)\n",
    "        loss = criterion(outputs, y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == y_).sum().item()\n",
    "        total += y_.size(0)\n",
    "\n",
    "    epoch_loss = train_loss / len(dataloader)\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_, y_ in dataloader:\n",
    "            X_, y_ = X_.to(DEVICE), y_.to(DEVICE)\n",
    "\n",
    "            outputs = model(X_)\n",
    "            loss = criterion(outputs, y_)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == y_).sum().item()\n",
    "            total += y_.size(0)\n",
    "\n",
    "    val_loss = val_loss / len(dataloader)\n",
    "    val_acc = 100.0 * correct / total\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec663c8-bd8a-4618-990c-c49dbace3ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]\n",
      "Train Loss: 1.7982 | Train Acc: 30.37%\n",
      "Val Loss:   1.4346 | Val Acc:   46.42%\n",
      "Epoch [2/20]\n",
      "Train Loss: 1.2190 | Train Acc: 55.24%\n",
      "Val Loss:   1.2493 | Val Acc:   57.21%\n",
      "Epoch [3/20]\n",
      "Train Loss: 0.9197 | Train Acc: 67.42%\n",
      "Val Loss:   0.9069 | Val Acc:   67.90%\n",
      "Epoch [4/20]\n",
      "Train Loss: 0.7667 | Train Acc: 73.13%\n",
      "Val Loss:   0.8474 | Val Acc:   70.41%\n",
      "Epoch [5/20]\n",
      "Train Loss: 0.6426 | Train Acc: 77.73%\n",
      "Val Loss:   0.6772 | Val Acc:   76.86%\n",
      "Epoch [6/20]\n",
      "Train Loss: 0.5702 | Train Acc: 80.52%\n",
      "Val Loss:   0.6349 | Val Acc:   79.50%\n",
      "Epoch [7/20]\n",
      "Train Loss: 0.5104 | Train Acc: 82.56%\n",
      "Val Loss:   0.5623 | Val Acc:   80.51%\n",
      "Epoch [8/20]\n",
      "Train Loss: 0.4607 | Train Acc: 84.20%\n",
      "Val Loss:   0.5302 | Val Acc:   82.29%\n",
      "Epoch [9/20]\n",
      "Train Loss: 0.4225 | Train Acc: 85.43%\n",
      "Val Loss:   0.5109 | Val Acc:   83.05%\n",
      "Epoch [10/20]\n",
      "Train Loss: 0.3895 | Train Acc: 86.62%\n",
      "Val Loss:   0.4999 | Val Acc:   83.37%\n",
      "Epoch [11/20]\n",
      "Train Loss: 0.3627 | Train Acc: 87.71%\n",
      "Val Loss:   0.4620 | Val Acc:   85.12%\n",
      "Epoch [12/20]\n",
      "Train Loss: 0.3385 | Train Acc: 88.46%\n",
      "Val Loss:   0.4103 | Val Acc:   86.57%\n",
      "Epoch [13/20]\n",
      "Train Loss: 0.3100 | Train Acc: 89.52%\n",
      "Val Loss:   0.4040 | Val Acc:   86.98%\n",
      "Epoch [14/20]\n",
      "Train Loss: 0.2929 | Train Acc: 89.83%\n",
      "Val Loss:   0.3829 | Val Acc:   87.32%\n",
      "Epoch [15/20]\n",
      "Train Loss: 0.2729 | Train Acc: 90.55%\n",
      "Val Loss:   0.4181 | Val Acc:   86.70%\n",
      "Epoch [16/20]\n",
      "Train Loss: 0.2538 | Train Acc: 91.36%\n",
      "Val Loss:   0.4487 | Val Acc:   86.05%\n",
      "Epoch [17/20]\n",
      "Train Loss: 0.2392 | Train Acc: 91.64%\n",
      "Val Loss:   0.3621 | Val Acc:   88.39%\n",
      "Epoch [18/20]\n",
      "Train Loss: 0.2277 | Train Acc: 92.04%\n",
      "Val Loss:   0.4122 | Val Acc:   87.36%\n",
      "Epoch [19/20]\n",
      "Train Loss: 0.2117 | Train Acc: 92.85%\n",
      "Val Loss:   0.4085 | Val Acc:   88.03%\n",
      "Epoch [20/20]\n",
      "Train Loss: 0.2027 | Train Acc: 92.89%\n",
      "Val Loss:   0.3749 | Val Acc:   88.04%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}]\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8888141-d493-4257-a9a5-b34e8d3357fc",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a17d3284-4155-45ae-99d4-be2613ea1a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg inference time: 0.5625 ms\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "num_samples = 100\n",
    "start_time = time.time()\n",
    "for _ in range(num_samples):\n",
    "    output = model(inp.to(DEVICE))\n",
    "end_time = time.time()\n",
    "\n",
    "infer_time = ((end_time - start_time) / num_samples) * 1000\n",
    "print(f'Avg inference time: {infer_time:.4f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9044053-ac49-496a-8e4f-2c90ac3fffd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 41.93 MB\n"
     ]
    }
   ],
   "source": [
    "model_size_mb = (sum(p.numel() for p in model.parameters()) * 4) / (1024**2)  # float32\n",
    "print(f\"Model size: {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a41f127-7c45-481d-9de6-162cf964ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0155d-d7bb-4a9a-a1c2-13d56833e23b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
