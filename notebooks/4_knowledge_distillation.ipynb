{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c330cf-90f2-428d-b5c3-aa2ba4a4d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f2cfb5-f2ce-4fa3-83e6-09395c7ccfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ad202-686c-4860-8547-06d7b92b1402",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4144ac-d34c-4583-8917-c7f45321810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "val_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                std=[0.2023, 0.1994, 0.2010])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f91332b8-7352-4dec-b020-aaceba6e9623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
    "val_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e595e7d5-14e1-4942-be25-19a60bcd6a44",
   "metadata": {},
   "source": [
    "# Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02daef98-a1d7-4f2a-a321-5ad02cf5c332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       1,728\n",
      "|    └─BatchNorm2d: 2-2                  128\n",
      "|    └─ReLU: 2-3                         --\n",
      "|    └─Conv2d: 2-4                       36,864\n",
      "|    └─BatchNorm2d: 2-5                  128\n",
      "|    └─ReLU: 2-6                         --\n",
      "|    └─MaxPool2d: 2-7                    --\n",
      "├─Sequential: 1-2                        --\n",
      "|    └─Conv2d: 2-8                       73,728\n",
      "|    └─BatchNorm2d: 2-9                  256\n",
      "|    └─ReLU: 2-10                        --\n",
      "|    └─Conv2d: 2-11                      147,456\n",
      "|    └─BatchNorm2d: 2-12                 256\n",
      "|    └─ReLU: 2-13                        --\n",
      "|    └─MaxPool2d: 2-14                   --\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─Conv2d: 2-15                      294,912\n",
      "|    └─BatchNorm2d: 2-16                 512\n",
      "|    └─ReLU: 2-17                        --\n",
      "|    └─Conv2d: 2-18                      589,824\n",
      "|    └─BatchNorm2d: 2-19                 512\n",
      "|    └─ReLU: 2-20                        --\n",
      "|    └─MaxPool2d: 2-21                   --\n",
      "├─Sequential: 1-4                        --\n",
      "|    └─Conv2d: 2-22                      1,179,648\n",
      "|    └─BatchNorm2d: 2-23                 1,024\n",
      "|    └─ReLU: 2-24                        --\n",
      "|    └─Conv2d: 2-25                      2,359,296\n",
      "|    └─BatchNorm2d: 2-26                 1,024\n",
      "|    └─ReLU: 2-27                        --\n",
      "|    └─MaxPool2d: 2-28                   --\n",
      "├─Sequential: 1-5                        --\n",
      "|    └─Linear: 2-29                      4,196,352\n",
      "|    └─ReLU: 2-30                        --\n",
      "|    └─Linear: 2-31                      2,098,176\n",
      "|    └─ReLU: 2-32                        --\n",
      "|    └─Linear: 2-33                      10,250\n",
      "=================================================================\n",
      "Total params: 10,992,074\n",
      "Trainable params: 10,992,074\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "class TeacherCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(TeacherCNN, self).__init__()\n",
    "        self.block1 = self._make_conv_block(in_ch=3,   out_ch=64)\n",
    "        self.block2 = self._make_conv_block(in_ch=64,  out_ch=128)\n",
    "        self.block3 = self._make_conv_block(in_ch=128, out_ch=256)\n",
    "        self.block4 = self._make_conv_block(in_ch=256, out_ch=512)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 2048),  # из 512x2x2 -> 2048\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def _make_conv_block(self, in_ch, out_ch):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x) \n",
    "        x = self.block2(x)  \n",
    "        x = self.block3(x)  \n",
    "        x = self.block4(x) \n",
    "\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "teacher_model = TeacherCNN(num_classes=10).to(DEVICE)\n",
    "teacher_model.load_state_dict(torch.load('./model.pt', weights_only=True))\n",
    "\n",
    "_ = summary(teacher_model, input_size=(BATCH_SIZE, 3, 32, 32), device=DEVICE, depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f4ec40-df14-4999-852b-ee9c45624fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       896\n",
      "|    └─BatchNorm2d: 2-2                  64\n",
      "|    └─ReLU: 2-3                         --\n",
      "|    └─MaxPool2d: 2-4                    --\n",
      "|    └─Conv2d: 2-5                       18,496\n",
      "|    └─BatchNorm2d: 2-6                  128\n",
      "|    └─ReLU: 2-7                         --\n",
      "|    └─MaxPool2d: 2-8                    --\n",
      "├─Sequential: 1-2                        --\n",
      "|    └─Linear: 2-9                       2,097,664\n",
      "|    └─ReLU: 2-10                        --\n",
      "|    └─Linear: 2-11                      5,130\n",
      "=================================================================\n",
      "Total params: 2,122,378\n",
      "Trainable params: 2,122,378\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "class StudentCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(StudentCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 16x16\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 8x8\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 8 * 8, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "student_model = StudentCNN(num_classes=10).to(DEVICE)\n",
    "\n",
    "_ = summary(student_model, input_size=(BATCH_SIZE, 3, 32, 32), device=DEVICE, depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80bd0a1-d26f-4f0a-8b6f-ce93aaa537af",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "884c58d2-de48-4fe8-ba64-12c75a667abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation_loss_fn(student_outputs, teacher_outputs, labels, alpha=0.5, T=2.0):\n",
    "    ce_loss = nn.functional.cross_entropy(student_outputs, labels)\n",
    "    kd_loss = nn.functional.kl_div(nn.functional.log_softmax(student_outputs / T, dim=1),        \n",
    "                       nn.functional.softmax(teacher_outputs / T, dim=1),\n",
    "                       reduction='batchmean') * (T * T)\n",
    "\n",
    "    return alpha * ce_loss + (1 - alpha) * kd_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5f113de-991a-41b1-996b-48a176f792f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X_, y_ in loader:\n",
    "            X_, y_ = X_.to(DEVICE), y_.to(DEVICE)\n",
    "            outputs = model(X_)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == y_).sum().item()\n",
    "            total += y_.size(0)\n",
    "    return 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddf4262c-8ec6-4591-8a05-ab39d03c941c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]\n",
      "Train Loss: 2.7757\n",
      "Train Acc:   47.17% | Val Acc:   58.38%\n",
      "Epoch [2/20]\n",
      "Train Loss: 2.0446\n",
      "Train Acc:   59.61% | Val Acc:   65.83%\n",
      "Epoch [3/20]\n",
      "Train Loss: 1.7780\n",
      "Train Acc:   64.48% | Val Acc:   67.75%\n",
      "Epoch [4/20]\n",
      "Train Loss: 1.6156\n",
      "Train Acc:   67.19% | Val Acc:   70.36%\n",
      "Epoch [5/20]\n",
      "Train Loss: 1.5076\n",
      "Train Acc:   69.18% | Val Acc:   72.18%\n",
      "Epoch [6/20]\n",
      "Train Loss: 1.4231\n",
      "Train Acc:   70.48% | Val Acc:   73.21%\n",
      "Epoch [7/20]\n",
      "Train Loss: 1.3465\n",
      "Train Acc:   72.04% | Val Acc:   73.07%\n",
      "Epoch [8/20]\n",
      "Train Loss: 1.2844\n",
      "Train Acc:   73.04% | Val Acc:   74.69%\n",
      "Epoch [9/20]\n",
      "Train Loss: 1.2454\n",
      "Train Acc:   73.67% | Val Acc:   74.25%\n",
      "Epoch [10/20]\n",
      "Train Loss: 1.2027\n",
      "Train Acc:   74.41% | Val Acc:   76.96%\n",
      "Epoch [11/20]\n",
      "Train Loss: 1.1604\n",
      "Train Acc:   75.05% | Val Acc:   76.59%\n",
      "Epoch [12/20]\n",
      "Train Loss: 1.1277\n",
      "Train Acc:   75.81% | Val Acc:   77.47%\n",
      "Epoch [13/20]\n",
      "Train Loss: 1.0942\n",
      "Train Acc:   76.30% | Val Acc:   77.06%\n",
      "Epoch [14/20]\n",
      "Train Loss: 1.0616\n",
      "Train Acc:   76.69% | Val Acc:   75.49%\n",
      "Epoch [15/20]\n",
      "Train Loss: 1.0337\n",
      "Train Acc:   77.27% | Val Acc:   78.99%\n",
      "Epoch [16/20]\n",
      "Train Loss: 1.0099\n",
      "Train Acc:   77.94% | Val Acc:   77.92%\n",
      "Epoch [17/20]\n",
      "Train Loss: 0.9988\n",
      "Train Acc:   77.97% | Val Acc:   77.40%\n",
      "Epoch [18/20]\n",
      "Train Loss: 0.9724\n",
      "Train Acc:   78.42% | Val Acc:   78.84%\n",
      "Epoch [19/20]\n",
      "Train Loss: 0.9496\n",
      "Train Acc:   78.96% | Val Acc:   79.92%\n",
      "Epoch [20/20]\n",
      "Train Loss: 0.9289\n",
      "Train Acc:   79.37% | Val Acc:   79.64%\n"
     ]
    }
   ],
   "source": [
    "teacher_model.eval()\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "alpha=0.5\n",
    "T=2.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    student_model.train()\n",
    "    train_loss = 0\n",
    "    correct, total = 0, 0\n",
    "    for X_, y_ in train_loader:\n",
    "        X_, y_ = X_.to(DEVICE), y_.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(X_)\n",
    "        student_outputs = student_model(X_)\n",
    "\n",
    "        # print(y_)\n",
    "        loss = distillation_loss_fn(student_outputs, teacher_outputs, y_,\n",
    "                                    alpha=alpha, T=T)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        _, preds = torch.max(student_outputs, 1)\n",
    "        correct += (preds == y_).sum().item()\n",
    "        total += y_.size(0)\n",
    "\n",
    "    train_acc = 100.0 * correct / total\n",
    "    val_acc = evaluate(student_model, val_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}]\")\n",
    "    print(f\"Train Loss: {train_loss/len(train_loader):.4f}\")\n",
    "    print(f\"Train Acc:   {train_acc:.2f}% | Val Acc:   {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8888141-d493-4257-a9a5-b34e8d3357fc",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd4a8511-4bc4-490b-b421-c4814cded690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 8.097MB\n"
     ]
    }
   ],
   "source": [
    "param_size = 0\n",
    "for param in student_model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in student_model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('Model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9044053-ac49-496a-8e4f-2c90ac3fffd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 2122378\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "params = count_parameters(student_model)\n",
    "print(\"Params:\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a17d3284-4155-45ae-99d4-be2613ea1a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Avg inference time: 0.3996 ms\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "student_model.to('cpu')\n",
    "num_samples = 100\n",
    "start_time = time.time()\n",
    "for _ in range(num_samples):\n",
    "    output = student_model(inp)\n",
    "end_time = time.time()\n",
    "\n",
    "infer_time = ((end_time - start_time) / num_samples) * 1000\n",
    "print(f'CPU Avg inference time: {infer_time:.4f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b83a82b9-de8c-4942-be02-c8a173a3283a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Avg inference time: 0.1437 ms\n"
     ]
    }
   ],
   "source": [
    "student_model.to(DEVICE)\n",
    "start_time = time.time()\n",
    "for _ in range(num_samples):\n",
    "    output = student_model(inp.to(DEVICE))\n",
    "end_time = time.time()\n",
    "\n",
    "infer_time = ((end_time - start_time) / num_samples) * 1000\n",
    "print(f'GPU Avg inference time: {infer_time:.4f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a41f127-7c45-481d-9de6-162cf964ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), './student_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
