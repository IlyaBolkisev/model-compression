{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c330cf-90f2-428d-b5c3-aa2ba4a4d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f2cfb5-f2ce-4fa3-83e6-09395c7ccfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ad202-686c-4860-8547-06d7b92b1402",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4144ac-d34c-4583-8917-c7f45321810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "val_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                std=[0.2023, 0.1994, 0.2010])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f91332b8-7352-4dec-b020-aaceba6e9623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
    "val_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e595e7d5-14e1-4942-be25-19a60bcd6a44",
   "metadata": {},
   "source": [
    "# Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02daef98-a1d7-4f2a-a321-5ad02cf5c332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       1,728\n",
      "|    └─BatchNorm2d: 2-2                  128\n",
      "|    └─ReLU: 2-3                         --\n",
      "|    └─Conv2d: 2-4                       36,864\n",
      "|    └─BatchNorm2d: 2-5                  128\n",
      "|    └─ReLU: 2-6                         --\n",
      "|    └─MaxPool2d: 2-7                    --\n",
      "├─Sequential: 1-2                        --\n",
      "|    └─Conv2d: 2-8                       73,728\n",
      "|    └─BatchNorm2d: 2-9                  256\n",
      "|    └─ReLU: 2-10                        --\n",
      "|    └─Conv2d: 2-11                      147,456\n",
      "|    └─BatchNorm2d: 2-12                 256\n",
      "|    └─ReLU: 2-13                        --\n",
      "|    └─MaxPool2d: 2-14                   --\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─Conv2d: 2-15                      294,912\n",
      "|    └─BatchNorm2d: 2-16                 512\n",
      "|    └─ReLU: 2-17                        --\n",
      "|    └─Conv2d: 2-18                      589,824\n",
      "|    └─BatchNorm2d: 2-19                 512\n",
      "|    └─ReLU: 2-20                        --\n",
      "|    └─MaxPool2d: 2-21                   --\n",
      "├─Sequential: 1-4                        --\n",
      "|    └─Conv2d: 2-22                      1,179,648\n",
      "|    └─BatchNorm2d: 2-23                 1,024\n",
      "|    └─ReLU: 2-24                        --\n",
      "|    └─Conv2d: 2-25                      2,359,296\n",
      "|    └─BatchNorm2d: 2-26                 1,024\n",
      "|    └─ReLU: 2-27                        --\n",
      "|    └─MaxPool2d: 2-28                   --\n",
      "├─Sequential: 1-5                        --\n",
      "|    └─Linear: 2-29                      4,196,352\n",
      "|    └─ReLU: 2-30                        --\n",
      "|    └─Linear: 2-31                      2,098,176\n",
      "|    └─ReLU: 2-32                        --\n",
      "|    └─Linear: 2-33                      10,250\n",
      "=================================================================\n",
      "Total params: 10,992,074\n",
      "Trainable params: 10,992,074\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.block1 = self._make_conv_block(in_ch=3,   out_ch=64)\n",
    "        self.block2 = self._make_conv_block(in_ch=64,  out_ch=128)\n",
    "        self.block3 = self._make_conv_block(in_ch=128, out_ch=256)\n",
    "        self.block4 = self._make_conv_block(in_ch=256, out_ch=512)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 2048),  # из 512x2x2 -> 2048\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def _make_conv_block(self, in_ch, out_ch):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x) \n",
    "        x = self.block2(x)  \n",
    "        x = self.block3(x)  \n",
    "        x = self.block4(x) \n",
    "\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = CNN(num_classes=10)\n",
    "model.load_state_dict(torch.load('./model.pt', weights_only=True))\n",
    "\n",
    "_ = summary(model, input_size=(BATCH_SIZE, 3, 32, 32), device=DEVICE, depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42c219fa-e479-4574-bb34-f5ac0ccd0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_and_save(model, num_clusters=16, outfile=\"compressed_model.npz\"):\n",
    "    compressed_dict = {}\n",
    "    device = next(model.parameters()).device \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for name, param in model.named_parameters():\n",
    "            w_np = param.cpu().numpy() \n",
    "            shape_ = w_np.shape\n",
    "            w_flat = w_np.ravel().reshape(-1, 1)  \n",
    "\n",
    "            effective_clusters = min(num_clusters, w_flat.shape[0])\n",
    "\n",
    "            kmeans = KMeans(n_clusters=effective_clusters, n_init=5, random_state=42)\n",
    "            kmeans.fit(w_flat)\n",
    "\n",
    "            centroids = kmeans.cluster_centers_.flatten() \n",
    "            labels = kmeans.labels_  \n",
    "\n",
    "            compressed_dict[f\"{name}_shape\"] = shape_\n",
    "            compressed_dict[f\"{name}_centroids\"] = centroids.astype(np.float32)\n",
    "            compressed_dict[f\"{name}_labels\"] = labels.astype(np.int32)\n",
    "    np.savez_compressed(outfile, **compressed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e67a4bbd-7e1c-43f7-8f59-f5676285c3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7347355"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_and_save(model, 16)\n",
    "os.path.getsize(\"compressed_model.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a7a0c29-641c-4995-9692-b6371e36e791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clustered_model(model_class, infile=\"compressed_model.npz\", num_classes=10):\n",
    "    data = np.load(infile)\n",
    "    model = model_class(num_classes=num_classes)\n",
    "\n",
    "    state_dict = model.state_dict()  \n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        shape_ = data[f\"{name}_shape\"]\n",
    "        centroids = data[f\"{name}_centroids\"]\n",
    "        labels = data[f\"{name}_labels\"]\n",
    "\n",
    "        w_rec = centroids[labels] \n",
    "        w_rec = w_rec.reshape(shape_)\n",
    "\n",
    "        state_dict[name] = torch.from_numpy(w_rec)\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25f7febd-0914-442f-8764-453eff88e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_clustered_model(CNN, infile=\"compressed_model.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8888141-d493-4257-a9a5-b34e8d3357fc",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9044053-ac49-496a-8e4f-2c90ac3fffd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 10992074\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "params = count_parameters(model)\n",
    "print(\"Params:\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a41f127-7c45-481d-9de6-162cf964ebd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Avg inference time: 2.5893 ms\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "num_samples = 100\n",
    "start_time = time.time()\n",
    "for _ in range(num_samples):\n",
    "    output = model(inp)\n",
    "end_time = time.time()\n",
    "\n",
    "infer_time = ((end_time - start_time) / num_samples) * 1000\n",
    "print(f'CPU Avg inference time: {infer_time:.4f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "562f13fc-d77c-48ac-ac89-2ccef6987756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Avg inference time: 1.1630 ms\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "\n",
    "model.to(DEVICE)\n",
    "start_time = time.time()\n",
    "for _ in range(num_samples):\n",
    "    output = model(inp.to(DEVICE))\n",
    "end_time = time.time()\n",
    "\n",
    "infer_time = ((end_time - start_time) / num_samples) * 1000\n",
    "print(f'GPU Avg inference time: {infer_time:.4f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28b0155d-d7bb-4a9a-a1c2-13d56833e23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.84\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_, y_ in val_loader:\n",
    "        X_, y_ = X_.to(DEVICE), y_.to(DEVICE)\n",
    "        outputs = model(X_)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == y_).sum().item()\n",
    "        total += y_.size(0)\n",
    "\n",
    "accuracy = 100.0 * correct / total\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5aa455-fa97-4810-aa6d-14bc0b8f12b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
